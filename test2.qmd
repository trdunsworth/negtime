---
title: "CAD Time Stamp Analysis"
date: "2025-02-05"
format:
  html:
    toc: true
    toc-title: "Contents"
    number-sections: true
    highlight-style: arrow
    
execute:
    echo: false
    warn_large_data: false
engine: knitr
---

```{r setup}
options(warn_large_data = FALSE)
```

```{r libraries}
#| echo: false
#| output: false
library(tidyverse)
library(tidymodels)
library(ggpubr)
library(rstatix)
library(car)
library(broom)
library(janitor)
library(Hmisc)
library(psych)
library(GGally)
library(FSA)
library(multcomp)
library(emmeans)
library(sur)
library(DescTools)
library(visdat)
library(nlme)
library(funModeling)
library(inspectdf)
library(dlookr)
library(merTools)
library(factoextra)
library(lubridate)
library(modeest)
library(raster)
library(moments)
library(ggthemes)
library(nortest)
library(MASS)
library(randtests)
library(summarytools)
library(report)
library(correlation)
library(knitr)
library(rmarkdown)
library(modelbased)
library(parameters)
library(performance)
library(insight)
library(fBasics)
library(knitr)
library(kableExtra)
library(viridis)
library(ggridges)
library(gt)
```

# CAD Time Stamp Analysis

The following analysis is desinged to look at the time stamps related to service calls for the past 13 months and determine the significance of event sequencing and investigate the challenges presented when calls for service are manipulated after the first call closure.

```{r load_dataset}
#| echo: false
#| output: false

df <- readxl::read_excel('data\\ItsAboutTime.xlsx')
```

## Author's Note

The data was harvested from the CentralSquare Enterprise CAD Reporting Database. The two database tables that were queried are Response_Master_Incident and Response_Master_Incident_Ext. These two tables contain all of the time stamps needed for the analysis. For this analysis, the data consists of call information, including the method of call reception, priority number, and the problem type from 01 January 2024 through 31 January 2025. This dataset consists of `{r} nrow(df)` rows prior to any cleaning of adjustments.

## Data Cleaning and Preparation

To ensure the data will be useful to us, the first step is cleaning. In this instance, after extracting the data from the archive database, cleaning was done in the Excel file, including removing the "NULL" values and replacing them with empty cells. This forces R to insert its own NULL value and allows it to correctly assign the data types to the columns. Here is a view of that so you can see what we have. 

```{r data_types}
#| echo: false

str(df)
```

This leaves us well positioned because we now have the character (chr) columns, numeric (num) columns, and time stamps (POSIXct) defined. The numeric columns will be expressed as BIGINT in the background which is what we want for now. 

### Column Definitions

The columns for this dataset are defined as follows:

::: {.callout-important}
Note that any negative values in the deltas occur when the time for the rightmost variable is earlier than the time recorded for the leftmost variable.
:::

::: {}
1. ID: *This is the ID column from the CAD. We will use it to isolate specific calls for further analyses.*
2. Reception: *This is how the call entered DECC. __'Null'__ Values will be changed to 'Not Recorded' for analytical purposes.*
3. Problem: *This is the final problem nature as updated by the parties working the call*
4. Priority: *This is the relative importance level assigned by DECC. This will be used for further analyses*
5. Agency: *This indicates if the call was for LAW, FIRE, or DEC.*
6. Jurisdiction: *This indicates for whom the call was run.*
7. Response_Date: *This, per CS, is the timestamp indicating when the ID was created and is frequently used, by them, as the __start__ of the call.*
8. Clock_Start: *This should be, per CS, the __actual__ starting point for the call.*
9. Phone_Start: *This timestamp identifies when the CAD acknowledged the start of the phone call for the event.*
10. Fixed_Phone_Start: *This timestamp also identifies when the CAD acknowledged the start of the phone call for the event, but is deemed __immutable__ by the software.*
11. First_Keystroke: *This timestamp identifies when the CAD software registers the first keystroke related to the event*
12. DELTA_RD_CST: *This is the difference, hence Î”, between the Response_Date and ClockStartTime columns.* 
13. DELTA_RD_TPU: *This is the difference between the Response_Date and the Time_PhonePickUp columns.*
14. DELTA_RD_FTPU: *This is the difference between the Response_Date and the Fixed_Time_PhonePickUp columns.*
15. DELTA_RD_FCTK: *This is the difference between the Response_Date and the Time_FirstCallTakingKeystroke columns.*
16. DELTA_CST_TPU: *This is the difference between the ClockStartTime and the Time_PhonePickUp columns.*
17. DELTA_CST_FTPU: *This is the difference between the ClockStartTime and the Fixed_Time_PhonePickUp columns.*
18. DELTA CST_FCTK: *This is the difference between the ClockStartTime and the Time_FirstCallTakingKeystroke columns.*
19. DELTA_TPU_FTPU: *This is the difference between the Time_PhonePickUp and Fixed_Time_PhonePickUp columns.*
20. DELTA_TPU_FCTK: *This is the difference between the Time_PhonePickUp and Time_FirstCallTakingKeystroke columns.*
21. DELTA_FTPU_FCTK: *This is the difference between the Fixed_Time_PhonePickUp and Time_FirstCallTakingKeystroke columns.*
22. Viewed: *This is defined by the vendor as the time the call was first viewed in the Call Taking Form.*
23. Queued: *This is the time when the call has been released to be dispatched by the calltaker.*
24. Fixed_Queued: *This is the __fixed__ time when the call has been released to be dispatched by the calltaker.*
25. DELTA_QUEUES: *This is the difference between the Time_CallEnteredQueue and Fixed_Time_CallEnteredQueue columns.*
26. Phone_End: *This is the time when the caller is released.*
27. Fixed_Phone_End: *This is the __fixed__ time when the caller is released.*
28. DELTA_CALLTAKING: *This is the difference between the Time_CallTakingComplete and Fixed_Time_CallTakingComplete columns.*
29. First_Dispatched: *This is the time when the dispatcher assigned the first unit to the call.*
30. First_Ack: *This is the time when the first unit acknowledges receiving the dispatched call.*
31. First_Enroute: *This is the time the first dispatched unit marks or is marked 'En Route' for the assigned call.*
32. First_Arrived: *This is the time the first dispatched unit marks or is marked 'Arrived' for the assigned call.*
33. First_Clear: *This is the time that the first unit clears or leaves the call after arrival.*
34. Call_Closed: *This is the time that the final unit is cleared from the call, closing the event out.*
35. Fixed_Call_Closed: *This is the __fixed__ time that the final unit is cleared from the call, closing the event out.* 
36. STEP_1: *This is the time difference between the ClockStartTime and the Time_PhonePickUp columns.*
37. STEP_2: *This is the time difference between the Time_PhonePickUp and the Time_FirstCallTakingKeystroke columns.*
38. STEP_2A: *This is the time difference between the Time_PhonePickUp and TimeCallViewed columns.*
39. STEP_2B: *This is the time difference between the TimeCallViewed and Time_FirstCallTakingKeystroke columns.*
40. STEP_3: *This is the time difference between the Time_FirstCallTakingKeystroke and Time_CallEnteredQueue columns.*
41. CALL_TIME: *This is the time difference between the Time_PhonePickUp and Time_CallTakingComplete columns.*
42. STEP_4: *This is the time difference between the Time_CallEnteredQueue and Time_First_Unit_Assigned columns.*
43. STEP_5: *This is the time difference between the Time_First_Unit_Assigned and TimeFirstUnitDispatchAcknowledged columns.*
44. STEP_6: *This is the time difference between the TimeFirstUnitDispatchAcknowledged and Time_First_Unit_Enroute columns.*
45. STEP_7: *This is the time difference between the Time_First_Unit_Enroute and Time_First_Unit_Arrived columns.*
46. STEP_8: *This is the time difference between the Time_First_Unit_Arrived and TimeFirstCallCleared columns.*
47. STEP_9: *This is the time difference between the TimeFirstCallCleared and Time_CallClosed columns.*
48. STEP_10: *This is the time difference between the Time_First_Unit_Arrived and Time_CallClosed columns.*
49. TOTAL_TIME_A: *This is the time difference between the Response_Date and Time_CallClosed columns.*
50. TOTAL_TIME_B: *This is the time difference between the ClockStartTime and Time_CallClosed columns.*
:::

::: {.callout-note}
Please note that there should not be, if calls are not re-opened, any delta between a time stamp and its 'Fixed' counterpart.
:::

In the list above, the Steps columns are meant to follow a call from the time the clock starts to the time the clock stops. I've identified a possible 10 step timing chain that would allow us to step through the history of a call. There are multiple possible steps for the second step depending on management preferences. Once we have established the chain time wise, then we can use these steps as a tool to investigate specific events and to get better analyses and insights from processes overall. This can also assist in trend analyses. Where there are no entries for some of these time points, we may need to create alternative elapsed time points to create our steps. Those decisions are part of this project's goals.

You will note there are some columns duplicated because they are meant to be used for different analyses using the same dataset. Traditionally, we shouldn't have to do this, but I chose to make this distinction for ease of use.

## Data Analysis

### Missing Data

Looking at the dataset, here is a graph of missing data:

```{r missing_data, warn_large_data=FALSE}
#| echo: false

library(naniar)
gg_miss_var(df)
```

The graph shows that we have over 70,000 calls where we never recorded an arrival to the event. We might need to add a disposition for the calls to see if there is a correlation between missing values and disposition codes. I've included a printout of the number of missing rows by column to assist in the numbers. 

```{r missing_data_count, warn_large_data = FALSE}
#| echo: false

apply(X = is.na(df), MARGIN = 2, FUN = sum)
```

With this information, we will need to address some of the NULL values in order to determine if there are any correlations. Immediately, you can see that the steps where the arrival time is missing also have missing values. 

```{r replace_nas}
#| echo: false
#| output: false

df$Reception <- tidyr::replace_na(df$Reception, "NOT RECORDED")
df$Problem <- tidyr::replace_na(df$Problem, "UNKNOWN")
df$Priority <- tidyr::replace_na(df$Priority, 99)
df$Jurisdiction <- tidyr::replace_na(df$Jurisdiction, "UNKNOWN")
```

We can repeat the graph to ensure that there are no longer any missing values for these four columns. 

```{r missing_data2, warn_large_data=FALSE}
#| echo: false

library(naniar)
gg_miss_var(df)
```

Now that we have those addressed, let's look at how many negative values we have across the thirteen month period. For this, I'm going to create a variable for each of the numeric columns, except Priority, and calculate a percentage of the data we do have that is negative and missing. That table can be found below:

```{r missing_and_negative_counts, warn_large_data = FALSE}
#| echo: false
#| output: false

delta1_neg <- sum(df$DELTA_RD_CST < 0, na.rm = TRUE)
delta2_neg <- sum(df$DELTA_RD_TPU < 0, na.rm = TRUE)
delta3_neg <- sum(df$DELTA_RD_FTPU < 0, na.rm = TRUE)
delta4_neg <- sum(df$DELTA_RD_FCTK < 0, na.rm = TRUE)
delta5_neg <- sum(df$DELTA_CST_TPU < 0, na.rm = TRUE)
delta6_neg <- sum(df$DELTA_CST_FTPU < 0, na.rm = TRUE)
delta7_neg <- sum(df$DELTA_CST_FCTK < 0, na.rm = TRUE)
delta8_neg <- sum(df$DELTA_TPU_FTPU < 0, na.rm = TRUE)
delta9_neg <- sum(df$DELTA_TPU_FCTK < 0, na.rm = TRUE)
delta10_neg <- sum(df$DELTA_FTPU_FCTK < 0, na.rm = TRUE)
delta_queues_neg <- sum(df$DELTA_QUEUES < 0, na.rm = TRUE)
delta_ct_neg <- sum(df$DELTA_CALLTAKING < 0, na.rm = TRUE)
delta_step1_neg <- sum(df$STEP_1 < 0, na.rm = TRUE)
delta_step2_neg <- sum(df$STEP_2 < 0, na.rm = TRUE)
delta_step2a_neg <- sum(df$STEP_2A < 0, na.rm = TRUE)
delta_step2b_neg <- sum(df$STEP_2B < 0, na.rm = TRUE)
delta_step3_neg <- sum(df$STEP_3 < 0, na.rm = TRUE)
call_time_neg <- sum(df$CALL_TIME < 0, na.rm = TRUE)
delta_step4_neg <- sum(df$STEP_4 < 0, na.rm = TRUE)
delta_step5_neg <- sum(df$STEP_5 < 0, na.rm = TRUE)
delta_step6_neg <- sum(df$STEP_6 < 0, na.rm = TRUE)
delta_step7_neg <- sum(df$STEP_7 < 0, na.rm = TRUE)
delta_step8_neg <- sum(df$STEP_8 < 0, na.rm = TRUE)
delta_step9_neg <- sum(df$STEP_9 < 0, na.rm = TRUE)
delta_step10_neg <- sum(df$STEP_10 < 0, na.rm = TRUE)
total_timea_neg <- sum(df$TOTAL_TIME_A < 0, na.rm = TRUE)
total_timeb_neg <- sum(df$TOTAL_TIME_B < 0, na.rm = TRUE)

delta1_na <- sum(is.na(df$DELTA_RD_CST))
delta2_na <- sum(is.na(df$DELTA_RD_TPU))
delta3_na <- sum(is.na(df$DELTA_RD_FTPU))
delta4_na <- sum(is.na(df$DELTA_RD_FCTK))
delta5_na <- sum(is.na(df$DELTA_CST_TPU))
delta6_na <- sum(is.na(df$DELTA_CST_FTPU))
delta7_na <- sum(is.na(df$DELTA_CST_FCTK))
delta8_na <- sum(is.na(df$DELTA_TPU_FTPU))
delta9_na <- sum(is.na(df$DELTA_TPU_FCTK))
delta10_na <- sum(is.na(df$DELTA_FTPU_FCTK))
delta_queues_na <- sum(is.na(df$DELTA_QUEUES))
delta_ct_na <- sum(is.na(df$DELTA_CALLTAKING))
delta_step1_na <- sum(is.na(df$STEP_1))
delta_step2_na <- sum(is.na(df$STEP_2))
delta_step2a_na <- sum(is.na(df$STEP_2A))
delta_step2b_na <- sum(is.na(df$STEP_2B))
delta_step3_na <- sum(is.na(df$STEP_3))
call_time_na <- sum(is.na(df$CALL_TIME))
delta_step4_na <- sum(is.na(df$STEP_4))
delta_step5_na <- sum(is.na(df$STEP_5))
delta_step6_na <- sum(is.na(df$STEP_6))
delta_step7_na <- sum(is.na(df$STEP_7))
delta_step8_na <- sum(is.na(df$STEP_8))
delta_step9_na <- sum(is.na(df$STEP_9))
delta_step10_na <- sum(is.na(df$STEP_10))
total_timea_na <- sum(is.na(df$TOTAL_TIME_A))
total_timeb_na <- sum(is.na(df$TOTAL_TIME_B))
```

| Column | Negative Rows | NA Rows | Neg Percentage | NA Percentage |
|:------:|:-------------:|:-------:|:--------------:|:-------------:|
| DELTA_RD_CST | `{r} print(delta1_neg)` | `{r} print(delta1_na)` | `{r} print(round(delta1_neg/(nrow(df)-delta1_na)*100, digits=2))` | `{r} print(round(delta1_na/nrow(df)*100, digits=2))` |
| DELTA_RD_TPU | `{r} print(delta2_neg)` | `{r} print(delta2_na)` | `{r} print(round(delta2_neg/(nrow(df)-delta2_na)*100, digits=2))` | `{r} print(round(delta2_na/nrow(df)*100, digits=2))` |
| DELTA_RD_FTPU | `{r} print(delta3_neg)` | `{r} print(delta3_na)` | `{r} print(round(delta3_neg/(nrow(df)-delta3_na)*100, digits=2))` | `{r} print(round(delta3_na/nrow(df)*100, digits=2))` |
| DELTA_RD_FCTK | `{r} print(delta4_neg)` | `{r} print(delta4_na)` | `{r} print(round(delta4_neg/(nrow(df)-delta4_na)*100, digits=2))` | `{r} print(round(delta4_na/nrow(df)*100, digits=2))` |
| DELTA_CST_TPU | `{r} print(delta5_neg)` | `{r} print(delta5_na)` | `{r} print(round(delta5_neg/(nrow(df)-delta5_na)*100, digits=2))` | `{r} print(round(delta5_na/nrow(df)*100, digits=2))` |
| DELTA_CST_FTPU | `{r} print(delta6_neg)` | `{r} print(delta6_na)` | `{r} print(round(delta6_neg/(nrow(df)-delta6_na)*100, digits=2))` | `{r} print(round(delta6_na/nrow(df)*100, digits=2))` |
| DELTA_CST_FCTK | `{r} print(delta7_neg)` | `{r} print(delta7_na)` | `{r} print(round(delta7_neg/(nrow(df)-delta7_na)*100, digits=2))` | `{r} print(round(delta7_na/nrow(df)*100, digits=2))` |
| DELTA_TPU_FTPU | `{r} print(delta8_neg)` | `{r} print(delta8_na)` | `{r} print(round(delta8_neg/(nrow(df)-delta8_na)*100, digits=2))` | `{r} print(round(delta8_na/nrow(df)*100, digits=2))` |
| DELTA_TPU_FCTK | `{r} print(delta9_neg)` | `{r} print(delta9_na)` | `{r} print(round(delta9_neg/(nrow(df)-delta9_na)*100, digits=2))` | `{r} print(round(delta9_na/nrow(df)*100, digits=2))` |
| DELTA_FTPU_FCTK | `{r} print(delta10_neg)` | `{r} print(delta10_na)` | `{r} print(round(delta10_neg/(nrow(df)-delta10_na)*100, digits=2))` | `{r} print(round(delta10_na/nrow(df)*100, digits=2))` |
| DELTA_QUEUES | `{r} print(delta_queues_neg)` | `{r} print(delta_queues_na)` | `{r} print(round(delta_queues_neg/(nrow(df)-delta_queues_na)*100, digits=2))` | `{r} print(round(delta_queues_na/nrow(df)*100, digits=2))` |
| DELTA_CALLTAKING | `{r} print(delta_ct_neg)` | `{r} print(delta_ct_na)` | `{r} print(round(delta_ct_neg/(nrow(df)-delta_ct_na)*100, digits=2))` | `{r} print(round(delta_ct_na/nrow(df)*100, digits=2))` |
| STEP_1 | `{r} print(delta_step1_neg)` | `{r} print(delta_step1_na)` | `{r} print(round(delta_step1_neg/(nrow(df)-delta_step1_na)*100, digits=2))` | `{r} print(round(delta_step1_na/nrow(df)*100, digits=2))` |
| STEP_2 | `{r} print(delta_step2_neg)` | `{r} print(delta_step2_na)` | `{r} print(round(delta_step2_neg/(nrow(df)-delta_step2_na)*100, digits=2))` | `{r} print(round(delta_step2_na/nrow(df)*100, digits=2))` |
| STEP_2A | `{r} print(delta_step2a_neg)` | `{r} print(delta_step2a_na)` | `{r} print(round(delta_step2a_neg/(nrow(df)-delta_step2a_na)*100, digits=2))` | `{r} print(round(delta_step2a_na/nrow(df)*100, digits=2))` |
| STEP_2B | `{r} print(delta_step2b_neg)` | `{r} print(delta_step2b_na)` | `{r} print(round(delta_step2b_neg/(nrow(df)-delta_step2b_na)*100, digits=2))` | `{r} print(round(delta_step2b_na/nrow(df)*100, digits=2))` |
| STEP_3 | `{r} print(delta_step3_neg)` | `{r} print(delta_step3_na)` | `{r} print(round(delta_step3_neg/(nrow(df)-delta_step3_na)*100, digits=2))` | `{r} print(round(delta_step3_na/nrow(df)*100, digits=2))` |
| CALL_TIME | `{r} print(call_time_neg)` | `{r} print(call_time_na)` | `{r} print(round(call_time_neg/(nrow(df)-call_time_na)*100, digits=2))` | `{r} print(round(call_time_na/nrow(df)*100, digits=2))` |
| STEP_4 | `{r} print(delta_step4_neg)` | `{r} print(delta_step4_na)` | `{r} print(round(delta_step4_neg/(nrow(df)-delta_step4_na)*100, digits=2))` | `{r} print(round(delta_step4_na/nrow(df)*100, digits=2))` |
| STEP_5 | `{r} print(delta_step5_neg)` | `{r} print(delta_step5_na)` | `{r} print(round(delta_step5_neg/(nrow(df)-delta_step5_na)*100, digits=2))` | `{r} print(round(delta_step5_na/nrow(df)*100, digits=2))` |
| STEP_6 | `{r} print(delta_step6_neg)` | `{r} print(delta_step6_na)` | `{r} print(round(delta_step6_neg/(nrow(df)-delta_step6_na)*100, digits=2))` | `{r} print(round(delta_step6_na/nrow(df)*100, digits=2))` |
| STEP_7 | `{r} print(delta_step7_neg)` | `{r} print(delta_step7_na)` | `{r} print(round(delta_step7_neg/(nrow(df)-delta_step7_na)*100, digits=2))` | `{r} print(round(delta_step7_na/nrow(df)*100, digits=2))` |
| STEP_8 | `{r} print(delta_step8_neg)` | `{r} print(delta_step8_na)` | `{r} print(round(delta_step8_neg/(nrow(df)-delta_step8_na)*100, digits=2))` | `{r} print(round(delta_step8_na/nrow(df)*100, digits=2))` |
| STEP_9 | `{r} print(delta_step9_neg)` | `{r} print(delta_step9_na)` | `{r} print(round(delta_step9_neg/(nrow(df)-delta_step9_na)*100, digits=2))` | `{r} print(round(delta_step9_na/nrow(df)*100, digits=2))` |
| STEP_10 | `{r} print(delta_step10_neg)` | `{r} print(delta_step10_na)` | `{r} print(round(delta_step10_neg/(nrow(df)-delta_step10_na)*100, digits=2))` | `{r} print(round(delta_step10_na/nrow(df)*100, digits=2))` |
| TOTAL_TIME_A | `{r} print(total_timea_neg)` | `{r} print(total_timea_na)` | `{r} print(round(total_timea_neg/(nrow(df)-total_timea_na)*100, digits=2))` | `{r} print(round(total_timea_na/nrow(df)*100, digits=2))` |
| TOTAL_TIME_B | `{r} print(total_timeb_neg)` | `{r} print(total_timeb_na)` | `{r} print(round(total_timeb_neg/(nrow(df)-total_timeb_na)*100, digits=2))` | `{r} print(round(total_timeb_na/nrow(df)*100, digits=2))` |

Because of the way the programming language processes our requests, I'm going to reverse the fields in a few of the areas where I have no negative time-to-event values to ensure that both directions are equal in value counts. 

``` {r missing_and_neg2, warn_large_data = FALSE}
#| echo: false
#| output: false

delta8a_neg <- sum(df$DELTA_TPU_FTPU > 0, na.rm = TRUE)
delta9a_neg <- sum(df$DELTA_TPU_FCTK > 0, na.rm = TRUE)
delta10a_neg <- sum(df$DELTA_FTPU_FCTK > 0, na.rm = TRUE)
delta_queuesa_neg <- sum(df$DELTA_QUEUES > 0, na.rm = TRUE)
delta_cta_neg <- sum(df$DELTA_CALLTAKING > 0, na.rm = TRUE)
```

| Column | Negative Rows | NA Rows | Neg Percentage | NA Percentage |
|:------:|:-------------:|:-------:|:--------------:|:-------------:|
| DELTA_TPU_FTPU2 | `{r} print(delta8a_neg)` | `{r} print(delta8_na)` | `{r} print(round(delta8a_neg/(nrow(df)-delta8_na)*100, digits=2))` | `{r} print(round(delta8_na/nrow(df)*100, digits=2))` |
| DELTA_TPU_FCTK2 | `{r} print(delta9a_neg)` | `{r} print(delta9_na)` | `{r} print(round(delta9a_neg/(nrow(df)-delta9_na)*100, digits=2))` | `{r} print(round(delta9_na/nrow(df)*100, digits=2))` |
| DELTA_FTPU_FCTK2 | `{r} print(delta10a_neg)` | `{r} print(delta10_na)` | `{r} print(round(delta10a_neg/(nrow(df)-delta10_na)*100, digits=2))` | `{r} print(round(delta10_na/nrow(df)*100, digits=2))` |
| DELTA_QUEUES2 | `{r} print(delta_queuesa_neg)` | `{r} print(delta_queues_na)` | `{r} print(round(delta_queuesa_neg/(nrow(df)-delta_queues_na)*100, digits=2))` | `{r} print(round(delta_queues_na/nrow(df)*100, digits=2))` |
| DELTA_CALLTAKING2 | `{r} print(delta_cta_neg)` | `{r} print(delta_ct_na)` | `{r} print(round(delta_cta_neg/(nrow(df)-delta_ct_na)*100, digits=2))` | `{r} print(round(delta_ct_na/nrow(df)*100, digits=2))` |


### Initial Observations

Initially, it should be noted that there are a lot of negative time-to-event values between the Response_Date and both of the timestamps for when the phone is picked up. This could imply that the Response_Date column is also being impacted, at times, when the call is reopened. If this is the case, then I would recommend using that column for fencing entries and, even then, with caution. You can also see a lot of negative values between the ClockStartTime and the phone pickups. Again, this implies, to me, that this column may not be the most accurate. From appearances, I would recommend future analyses start with the Fixed_Time_PhonePickup as the initial point and disregard the call start time. 

I am pleased to see that there are no negative time-to-event values between the Time_PhonePickUp and Fixed_Time_PhonePickUp columns. That implies that there are no issues with reopening calls there. I would recommend using the *Fixed* value whenever possible. Those are implied to be immutable per CentralSquare. I am also pleased to see that see there are no negative time-to-event values for the span between the phone pickup and the first calltaking keystroke. The only drawback I saw is in the number of rows missing for both the Time_PhonePickUp and Fixed_Time_PhonePickUp columns. There are `{r} print(sum(is.na(df$Phone_Start)))` and `{r} print(sum(is.na(df$Fixed_Phone_Start)))` missing rows respectively. These represent `{r} print(round(sum(is.na(df$Phone_Start))/nrow(df)*100, digits=2))` percent and `{r} print(round(sum(is.na(df$Fixed_Phone_Start))/nrow(df)*100, digits=2))` percent of the columns missing respectively. The good news is that, at under 5% of the dataset, initial EDA and other preliminary work can safely discard those columns. 

We should abandon the TimeCallViewed column. There are too many missing values. Attempting to use this column in time-to-event analyses resulted in over 40% of those events having missing data. While abandoned calls may be considered censored in survival analyses, applying censoring rules to these columns renders that column inert analytically. Therefore abandoning the column is the only analytical course of action.  

Another positive observation was a lack of negative values between the time stamps for calls entering the dispatch queue. Additionally, there were no missing values between the two columns either. So we appear to be able to use either column, again I recommend defaulting to the *Fixed* alternative for analytical purposes. 

The reversals show that where there were no negative time-to-event values between the phone pickup timestamps, the first entering queue timestamps, the completion of the call taking process timestamps. This is heartening and allows us to select either of the two timestamps for the same event. The interesting thing to note is that there is a delta in about 50% of cases between the phone pickup and the first call taking keystroke. This confirms the idea that we can build a call flow process for survival analyses that starts with the phone pickup and continues with the first keystroke. It also shows that nearly half of the time, the timestamps for phone pickup and first keystroke are identical.

### EDA

Now that we know what we're facing with respect to negative values and missing values, the first stage of analysis can take place. This first summary will leave the negative values in place, but will remove the missing values from the calculation.

```{r elapse_summary}
numerics <- df[, c("DELTA_RD_CST", "DELTA_RD_TPU", "DELTA_RD_FTPU", "DELTA_RD_FCTK", "DELTA_CST_TPU", "DELTA_CST_FTPU", "DELTA_CST_FCTK", "DELTA_TPU_FTPU", "DELTA_TPU_FCTK", "DELTA_FTPU_FCTK", "DELTA_QUEUES", "DELTA_CALLTAKING", "STEP_1", "STEP_2", "CALL_TIME", "STEP_3", "STEP_4", "STEP_5", "STEP_6", "STEP_7", "STEP_8", "STEP_9", "STEP_10", "TOTAL_TIME_A", "TOTAL_TIME_B")]

# Custom summary function
custom_summary <- function(column) {
  c(
    Minimum = round(min(column, na.rm = TRUE), 2),
    Mean = round(mean(column, na.rm = TRUE), 2),
    Median = round(median(column, na.rm = TRUE), 2),
    Q1 = round(quantile(column, 0.25, na.rm = TRUE), 2),
    Q3 = round(quantile(column, 0.75, na.rm = TRUE), 2),
    Maximum = round(max(column, na.rm = TRUE), 2),
    Std_Dev = round(sd(column, na.rm = TRUE), 2),
    Skewness = round(e1071::skewness(column, na.rm = TRUE), 2),
    Kurtosis = round(e1071::kurtosis(column, na.rm = TRUE), 2)
  )
}

# Apply the summary function to each column in the subset
summary_table <- t(sapply(numerics, custom_summary))

# Convert to data frame for better handling
summary_table <- as.data.frame(summary_table)

# Add variable names as row names
summary_table$Variable <- rownames(summary_table)

# Reorder columns to place 'Variable' at the beginning
# summary_table <- summary_table[, c("Variable", names(summary_table)[-ncol(summary_table)])]
summary_table <- summary_table[, c(names(summary_table)[-ncol(summary_table)])]

summary_table %>%
    kable(format = "markdown", caption = "Weekly Elapsed Time Summary Table") %>%
    kable_styling(bootstrap_options = c("striped", "hover"))
```